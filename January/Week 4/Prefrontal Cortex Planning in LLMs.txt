A PREFRONTAL CORTEX-INSPIRED ARCHITECTURE
FOR PLANNING IN LARGE LANGUAGE MODELS

30 Sep 2023

Abstract
- LLMs struggle with multi-step reasoning / goal-directed planning.
- We take inspiration from the human brain:
- Planning is accomplished via the recurrent interaction of specialized modules in the prefrontal cortex (PFC)
- Specialized modules perform functions like:
- conflict monitoring
- state prediction
- state evaluation
- task decomposition 
- task coordination
- LLMs are sometimes capable of carrying out these functions in isolation, but struggle to autonomously coordinate them in the service of a goal.
- We propose a black box architecture improves planning through the interaction of specialized PFC-inspired modules that break down a larger problem into multiple brief automated calls to the LLM


Introduction
- Planning is generally thought to depend on the prefrontal cortex (PFC)
- PFC is broadly involved in executive function, decision-making, and reasoning.
- PFC has subregions or modules to perform specialized functions.
- Human planning emerges through the coordinated and recurrent interactions among these specialized PFC modules, rather than through the activity of a single, monolithic system.

- It is suggested that the coordinated activity of multiple PFC subregions performs tree search during planning.
- Thus, our approach combines action proposal, state prediction, and state evaluation to perform tree search.

- Each individual module plays an important role in the overall architecture's performance.


Approach

Modules
- TaskDecomposer:
1. Receives current state x and goal y
2. Generate subgoals Z to allow the agent to gradually work toward the final goal
3. Currently, only utilized to generate a single intermediate goal, though in the future, we envision it will be useful to generate a series of multiple subgoals

- Actor:
1. Recieves current state x and subgoal z and proposes B potential actions: A = a1, ... , aB
2. Actor can receive feedback e from the Monitor about its proposed actions.

- Monitor:
1. Assesses the actions proposed by the Actor to determine whether they are valid (eg. violate the rules of the task)
2. Emits an assessment of validity s, and feedback e in the event the action is deemed invalid.

- Predictor:
1. Receives current state x and proposed action a, and predicts the resulting next state ~x~.

- Evaluator:
1. Receives next-state prediction ~x~ and produces an estimate of its value v in the context of goal y.
2. We do this by prompting the Evaluator to estimate the minimum number of steps required to reach the goal (or subgoal) from the current state.

- TaskCoordinator:
1. Receives current state x and subgoal z and emits assessment O of whether the subgoal has been achieved.
2. When all subgoals (including final goal) have been achieved, the plan is emitted to the environment as a series of actions.

Action Proposal Loop
- Actor and Monitor interact via the ProposeAction function.
- Actor proposes actions, which are gated by the Monitor.
- If Monitor determines that the actions are invalid (eg, violate the rules of the task), feedback is provided to the Actor, which then proposes an alternative action.

Search Loop
- ProposeAction is further embedded in a Search loop
- Actions emmitted by ProposeAction are passed to the Predictor, which predicts the states that will result from these actions.
- A limited tree search is then performed, starting from the current state and then exploring B branches recursively to a depth of L layers.

Plan Generation
- To generate a plan, a set of subgoals is generated by the TaskDecomposer based on the final goal and current state.
- These subgoals are then pursued one at a time, utilizing the Search loop to generate actions until the TaskCoordinator determines the subgoal has been achieved
- ...