Generative Agents: Interactive Simulacra of Human Behavior

Abstract
Generative Agents are capable of complex interactions within the environment.
The components of the architecture: observation, planning, reflection all contribute critically to the believability of agent behavior.

1 Introduction
Fully general agents that ensure long-term coherence would be better suited by architectures that manage constantly-growing memories as new interactions, conflicts, and events arise and fade over time while handling cascading social dynamics that unfold between multiple agents.

A successful approach requires:
- Retrieval of relevant events / interactions over a long period of time
- Reflection over these memories to generalize & draw higher level inferences
- Plans and reactions which apply our reflections that make sense in the moment.

Generative agents: agents that draw on generative models to simulate believable human behavior & demonstrate they can produce believable simulacra of both individual and group behavior properties.

Architecture:
- Memory stream
- Reflection
- Planning

3 Generative Agent Behavior and Interaction
3.1 Agent Avatar & Communication
25 unique agents live in Smallville
One paragraph of semicolon delimited seed memories depicts each agents identity

3.1.1 Inter-Agent Communication
Interact with the world through their actions
Interact with each other through natural language
At each time step of the sandbox, the agents output a natural language statement describing their current action “Isabella is writing in her journal”
The sentence is then translated into concrete movements that affect the sandbox world.
The sentence is displayed as a set of emojis to the simulator.

Agents communicate with each other in full natural language. They are aware of agents in their vicinity and the generative architecture determines whether or not they engage in conversation.

3.1.2 User Controls
The user can communicate with an agent by specifying a persona they should address the user as.
To directly command an agent you can tell him it’s his “inner voice” speaking.

3.2 Environmental Interaction
Smallville has all of the common places in a town.
Each agents living space has all of the common amenities of a bedroom.
Agents move just like they would in a video game.
When an agent wants to travel to a new location, we calculate the time it takes, and move him step by step along with the until he reaches his destination.
Users can enter the sandbox world as an agent operating in it. 
Agents and users can influence the state of objects in the environment (occupy a bed, use up food in a fridge)

3.3 Example “Day in a Life”
Starting from single paragraph description, generative agents begin planning their days. As time passes, their behaviors evolve as they interact with one another.

3.4 Emergent Social Behaviors
3.4.1 Information diffusion
As agents notice each other, they may engage in dialogue. 
As they do so, information is distributed among them.

3.4.2 Relationship Memory
Agents form new relationships over time & they remember their interactions. 

3.4.3 Coordination
Generative Agents coordinate with each other.

4 Generative Agent Architecture
Memory stream: a database that maintains a comprehensive record of an agents experience. 
From the memory stream, relevant records are retrieved to plan the agents actions and react appropriately.
Records are recursively synthesized into higher and higher level reflections to guide behavior. 
Everything is recorded and reasoned over

4.1 Memory and Retrieval
The Memory Stream maintains a comprehensive record of the agents experience.
It is a list of memory objects where each object contains a natural language description, a creation time stamp and a most recent access time stamp.
Most basic element of the memory stream: an observation (an event directly perceived by an agent) can be observations about other agents or about the environment

Retrieval function takes current situation as input and returns a subset of the memory stream to pass on to the model

Three main components: 

Recency — higher score to memory objects that were recently accessed (exponential decay function)
Importance — 1-10 rating
Relevance — Relation to current situation. We create a query to search, then generate cosine similarity

To calculate final retrieval score, we normalize recency, relevance and importance all to a [0,1] scale, using min-max scaling.
The top ranked memories that fit within the context window are included in the prompt.

4.2 Reflection

Generative Agents with only observational capacity struggle to generalize or make inferences. 
We reflect to help make these generalizations / inferences.

Reflections are higher level, more abstract thoughts generated by the agent. They are a type of memory, so included alongside other observations in retrieval. 

Reflections are generated periodically: every time the importance score of the most recent interactions has surpassed 150.

First step: what to reflect on?
Identify questions to ask given the agent recent experiences
Query the 100 most recent records in Memory stream.
“Given info above what are 3 high level questions we can reflect on?”
Use these questions as queries for retrieval & gather relevant memories for each question. 

Then prompt the LLM to extract insights & cite the records that served as evidence. 

Parse and store the statement as a reflection in the memory stream, including pointers to the memory objects that were cited.

Reflection allows agents to reflect on observations as well as reflect on other reflections. Creates a tree of thoughts.

4.3 Planning and Reacting
Agents need to plan over a longer time horizon to ensure their sequence of actions is coherent + believable.

Plans describe a future sequence of actions for the agent, and help keep the agent's behavior consistent over time.
Plan: location, start time, duration

Plans are stored in the memory stream & are included in the retrieval process. Agent can consider observations, reflections and plans all together when deciding how to behave. Plans may change midstream.

To generate detailed, interesting plans, the approach is top-down and recursively generates more detial. 

Agent generates tentative plan at beginning of the day, saves it to memory stream, then recursively decomposes it to create finer-grained actions. First into hour-long chunks of actions--then to 5-15 min chunks

4.3.1 Reacting / Updating plans
Gen Agents operate in an action loop where at each time step they perceive the world around them and those perceptions are stored in memory stream.
We prompt the LM to decide whether the agent should continue with the existing plan or react.

If react, we regenerate the agent's existing plan

4.3.2 Dialogue
Agents converse as they interact with each other in utterances.
Utterances are conditioned by with the summarized memory about the other agent.

5 Sandbox Environment Implementation
Built using the Phaser web game dev framework.
Server maintains a JSON datastructure that contains information about each agent in the sandbox.

5.1 Structured World Environments to NL and Back Again
Agents build individual tree representations of the environment as they navigate it.
Environment tree captures the spaces and objects that the agent should be aware of: rooms, objects, workplace, commonly visited stores / shops.
We update this tree as agents navigate the world to reflect newly perceived areas.